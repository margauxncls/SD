{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD-TSIA 2011\n",
    "## Practical Work #01\n",
    "---\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from scipy.linalg import norm, solve\n",
    "from scipy.optimize import check_grad\n",
    "\n",
    "from tp_reglog_utils import load_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_test, y_test = load_data()\n",
    "n=len(y)\n",
    "rho = 1/n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Tikhonov regularization\n",
    "#### Question 3.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By computing the partial derivatives, we have :\n",
    "\n",
    "$$ \\nabla f_1(\\omega_0, \\omega) = \n",
    "\\begin{pmatrix}\n",
    "- \\frac{1}{n} \\sum^n_{i=1}{y_i\\sigma\\left(-y_i\\left(x_i^T\\omega + \\omega_0 \\right)\\right)} \\\\\n",
    "\\\\\n",
    "- \\frac{1}{n} \\sum^n_{i=1}{y_ix_{1i}\\sigma\\left(-y_i\\left(x_i^T\\omega + \\omega_0 \\right)\\right)} + \\rho \\omega_1\\\\\n",
    "\\vdots \\\\\n",
    "- \\frac{1}{n} \\sum^n_{i=1}{y_ix_{pi}\\sigma\\left(-y_i\\left(x_i^T\\omega + \\omega_0 \\right)\\right)} + \\rho \\omega_p \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "With $\\sigma(x)=\\frac{1}{1+e^{-x}}$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Hessian matrix, we should compute :  \n",
    "$$  \\frac{\\partial^2 f_1}{\\partial \\omega_p \\partial \\omega_q} (\\omega_0, \\omega), ~~~~\\forall p,q \\in \\llbracket 0; n \\rrbracket$$\n",
    "\n",
    "For $p \\neq 0, q \\neq 0$ :\n",
    "$$ \\frac{\\partial^2 f_1}{\\partial \\omega_p \\partial \\omega_q} (\\omega_0, \\omega) = \n",
    "\\frac{1}{n} \\sum^n_{i=1}{y_i^2 x_{pi}x_{qi}\\sigma'\\left(-y_i\\left(x_i^T\\omega + \\omega_0 \\right)\\right)} + \\rho \\delta_{p,q}$$\n",
    "\n",
    "With $\\sigma'(x)=\\frac{e^{-x}}{(1+e^{-x})^2}$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we obtain the following Hessian matrix :\n",
    "\n",
    "$$ \\boxed{\\nabla^2 f_1(\\omega_0, \\omega) = \\frac{1}{n} \n",
    "\\begin{pmatrix} \n",
    "    \\sum^n_{i=1}{y_i^2 \\sigma'\\left(-y_i\\left(x_i^T\\omega + \\omega_0 \\right)\\right)} &\n",
    "    \\sum^n_{i=1}{y_i^2 x_{1i}\\sigma'\\left(-y_i\\left(x_i^T\\omega + \\omega_0 \\right)\\right)} &\n",
    "    \\cdots &\n",
    "    \\sum^n_{i=1}{y_i^2 x_{pi}\\sigma'\\left(-y_i\\left(x_i^T\\omega + \\omega_0 \\right)\\right)} \\\\\n",
    "    \\\\\n",
    "    \\sum^n_{i=1}{y_i^2 x_{1i}\\sigma'\\left(-y_i\\left(x_i^T\\omega + \\omega_0 \\right)\\right)} &\n",
    "    \\sum^n_{i=1}{y_i^2 x_{1i}^2\\sigma'\\left(-y_i\\left(x_i^T\\omega + \\omega_0 \\right)\\right)} + n\\rho &\n",
    "    \\cdots &\n",
    "    \\sum^n_{i=1}{y_i^2 x_{pi}x_{1i}\\sigma'\\left(-y_i\\left(x_i^T\\omega + \\omega_0 \\right)\\right)} \\\\\n",
    "    \\\\\n",
    "    \\vdots & \\vdots & \\ddots &\\vdots \\\\\n",
    "    \\\\\n",
    "    \\sum^n_{i=1}{y_i^2 x_{pi}\\sigma'\\left(-y_i\\left(x_i^T\\omega + \\omega_0 \\right)\\right)} &\n",
    "    \\sum^n_{i=1}{y_i^2 x_{pi}x_{1i}\\sigma'\\left(-y_i\\left(x_i^T\\omega + \\omega_0 \\right)\\right)}  &\n",
    "    \\cdots &\n",
    "    \\sum^n_{i=1}{y_i^2 x_{pi}^2\\sigma'\\left(-y_i\\left(x_i^T\\omega + \\omega_0 \\right)\\right)} + n\\rho\n",
    "    \n",
    "\\end{pmatrix}}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hessian matrix has all its components strictly positive, as the sum of products of positive numbers. The function is therefore convex."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_f1(w_tild, x_matrix, y_array):\n",
    "    \"\"\" return the value of f, its gradient and Hessian matrix, with w_tild a (p+1)-array, x_matrix a (n, p+1)-matrix, y_array a n-array and rho a scalar\"\"\"\n",
    "    n = x_matrix.shape[0]\n",
    "    assert n==(len(y_array)), 'verify x and y dimensions'\n",
    "    \n",
    "\n",
    "    p = x_matrix.shape[1] - 1 \n",
    "    assert p+1==len(w_tild), 'dimension w'\n",
    "    \n",
    "    def value(w_tild) :\n",
    "        \"\"\" return the value of f, where w is an 1d-array and w_0 a scalar\"\"\"\n",
    "        w = np.concatenate(([0], w_tild[1:]))\n",
    "        w_0  = w_tild[0]\n",
    "\n",
    "        norm2 = w @ w\n",
    "        sum_f1 = 0\n",
    "        for i in range(n):\n",
    "            sum_f1 += np.log(1+ np.exp(-y_array[i]*(x_matrix[i]@w + w_0)))\n",
    "            \n",
    "        return (1/n)*sum_f1 + (rho/2)*norm2**2\n",
    "\n",
    "    def sigma(x):\n",
    "        \"\"\" return the value in x of sigma function\"\"\"\n",
    "        return 1/(1+ np.exp(-x))\n",
    "\n",
    "    def sigma_d(x):\n",
    "        \"\"\" return the value in x of the derivate function\"\"\"\n",
    "        return np.exp(-x)/((1+np.exp(-x))**2)\n",
    "\n",
    "    def grad(w_tild):\n",
    "        \"\"\" return the gradient of the function\"\"\"\n",
    "        w = np.concatenate(([0], w_tild[1:]))\n",
    "        w_0  = w_tild[0]\n",
    "        gradient = np.zeros(len(w))\n",
    "\n",
    "        for q in range(p+1):\n",
    "            s = 0\n",
    "            for i in range (n):\n",
    "                s += y_array[i]*x_matrix[i,q]*sigma(-y_array[i]*(x_matrix[i]@w + w_0)) \n",
    "            gradient[q] = -(1/n)*s + rho*w[q]\n",
    "        return gradient\n",
    "\n",
    "    #To check if our gradient is correct\n",
    "    assert (check_grad(value,grad,np.zeros(p+1)< 1e-3)), 'issue with gradient verification'\n",
    "\n",
    "    def hessian_matrix(w_tild):\n",
    "        \"\"\"return the hessian matrix of f\"\"\"\n",
    "        w = np.concatenate(([0], w_tild[1:]))\n",
    "        w_0  = w_tild[0]\n",
    "\n",
    "        matrix = np.zeros((p+1,p+1))\n",
    "\n",
    "        for l in range (p+1):\n",
    "            for c in range(l+1):\n",
    "                s = 0\n",
    "                for i in range (n):\n",
    "                    s += ((y_array[i]**2)*(x_matrix[i,l]*x_matrix[i,c]))*sigma_d(-y_array[i]*(x_matrix[i]@w + w_0)) \n",
    "                \n",
    "                if l != c:\n",
    "                    matrix[l,c] = (1/n)*s\n",
    "                    matrix[c,l] = (1/n)*s\n",
    "\n",
    "                else:\n",
    "                    if l != 0:\n",
    "                        matrix[c,l] = (1/n)*s + rho\n",
    "                    else :\n",
    "                        matrix[c,l] = (1/n)*s\n",
    "        return matrix\n",
    "\n",
    "    return value(w_tild), grad(w_tild), hessian_matrix(w_tild)                "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method_exact_line_search(f,grad,h_matrix,x0):\n",
    "    \"\"\"implements the Newton method with f the function we are optimizing, grad its gradient and h_matrix its Hessian matrix\"\"\"\n",
    "    max_iter = 500\n",
    "    sigma = 0.4\n",
    "    k = 0\n",
    "    epsilon = 10e-10\n",
    "\n",
    "    def exact_line_search_method(f, x, alpha, p):\n",
    "        condition = np.dot(f(x+alpha*p),p) == 0\n",
    "        return condition\n",
    "\n",
    "    while k < max_iter:\n",
    "        grad_k = grad(x0)\n",
    "        h_matrix_k = h_matrix(x0)\n",
    "        d_k = -1.0*np.linalg.solve(h_matrix_k,grad_k)\n",
    "        if np.linalg.norm(d_k) < epsilon :\n",
    "            break\n",
    "        m = 0\n",
    "        m_k = 0\n",
    "        while m < 20 :\n",
    "            if exact_line_search_method(g,x0,rho**m,d_k):\n",
    "                m_k = m\n",
    "                break\n",
    "            m += 1\n",
    "        x0 += rho**m_k*d_k\n",
    "        k += 1 #going to the next iteration\n",
    "    print(\"xk = \",x0)\n",
    "    print(\"f(xk) = \", round(f(x0),3))\n",
    "    print(\"Nb of Iterations = \", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.zeros(576)\n",
    "value, grad, h_matrix = analyze_f1(w, X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExactLineSearchMethod(f, x, alpha, p):\n",
    "    condition = np.dot(f(x+alpha*p),p) == 0\n",
    "    return condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NewtonMethodExactLineSearch(f,g,h,x0):\n",
    "    #f is f(x) we are optimizing\n",
    "    #g is the gradient of f\n",
    "    #H is the Hessian of f\n",
    "    maxNbOfIter = 500\n",
    "    sigma = 0.4\n",
    "    k = 0\n",
    "    epsilon = 10e-10\n",
    "    while k < maxNbOfIter:\n",
    "        gk = g(x0)\n",
    "        Hk = H(x0)\n",
    "        dk = -1.0*np.linalg.solve(Hk,gk)\n",
    "        if np.linalg.norm(dk) < epsilon :\n",
    "            break\n",
    "        m = 0\n",
    "        mk = 0\n",
    "        while m < 20 :\n",
    "            if ExactLineSearchMethod(g,x0,rho**m,dk):\n",
    "                mk = m\n",
    "                break\n",
    "            m += 1\n",
    "        x0 += rho**mk*dk\n",
    "        k += 1 #going to the next iteration\n",
    "    print(\"xk = \",x0)\n",
    "    print(\"f(xk) = \", round(f(x0),3))\n",
    "    print(\"Nb of Iterations = \", k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c84de3fc748a1d9bbcf83120cc7ef8f72e42d9020596d23632446b283e47ab12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
